{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set() #sets the matplotlib style to seaborn style\n",
    "\n",
    "from scipy.ndimage import convolve1d\n",
    "from scipy.io import loadmat \n",
    "from scipy.ndimage import convolve1d\n",
    "from scipy.signal import butter\n",
    "from scipy.signal import sosfiltfilt\n",
    "from scipy.signal import welch\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define the parameters RERUN to rerun all the notebook\n",
    "RERUN = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files loaded!\n"
     ]
    }
   ],
   "source": [
    "# Root directory containing the s1, s2, ..., s27 folders\n",
    "root_dir = \"./data\"\n",
    "\n",
    "# Dictionary to store all loaded .mat files\n",
    "all_data = {}\n",
    "\n",
    "# Loop through directories s1 to s27\n",
    "for i in range(1, 28):\n",
    "    subdir = os.path.join(root_dir, f\"s{i}\")  # Construct subdirectory path\n",
    "    \n",
    "    if os.path.exists(subdir):  # Ensure the subdirectory exists\n",
    "        # Load all .mat files in the subdirectory\n",
    "        for file in os.listdir(subdir):\n",
    "            if file.endswith(\".mat\"):  # Only process .mat files\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                all_data[file] = loadmat(file_path)  # Use the filename as the key\n",
    "\n",
    "print(\"All files loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Define parameters\u001b[39;00m\n\u001b[0;32m      2\u001b[0m mov_mean_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m\n\u001b[1;32m----> 3\u001b[0m mov_mean_weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(mov_mean_length) \u001b[38;5;241m/\u001b[39m mov_mean_length\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize a dictionary to store the processed data\u001b[39;00m\n\u001b[0;32m      6\u001b[0m processed_data \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "mov_mean_length = 25\n",
    "mov_mean_weights = np.ones(mov_mean_length) / mov_mean_length\n",
    "\n",
    "# Initialize a dictionary to store the processed data\n",
    "processed_data = {}\n",
    "\n",
    "# Iterate over all subjects/files\n",
    "for subject, data in all_data.items():\n",
    "    print(f\"Processing {subject}...\")\n",
    "    \n",
    "    # Extract variables from the .mat file\n",
    "    stimulus = data[\"stimulus\"].flatten()  # Ensure 1D\n",
    "    repetition = data[\"repetition\"].flatten()  # Ensure 1D\n",
    "    emg = data[\"emg\"]  # EMG signals (assume it's 2D)\n",
    "\n",
    "    # Get the number of stimuli and repetitions (assume these are known or can be deduced)\n",
    "    n_stimuli = int(np.max(stimulus))  # Number of unique stimuli\n",
    "    n_repetitions = int(np.max(repetition))  # Number of unique repetitions\n",
    "\n",
    "    # Initialize data structures for this subject\n",
    "    emg_windows = [[None for _ in range(n_repetitions)] for _ in range(n_stimuli)]\n",
    "    emg_envelopes = [[None for _ in range(n_repetitions)] for _ in range(n_stimuli)]\n",
    "\n",
    "    # Process each stimulus and repetition\n",
    "    for stimuli_idx in range(n_stimuli):\n",
    "        for repetition_idx in range(n_repetitions):\n",
    "            # Logical indexing to extract the corresponding EMG data\n",
    "            idx = np.logical_and(\n",
    "                stimulus == stimuli_idx + 1, \n",
    "                repetition == repetition_idx + 1\n",
    "            ).flatten()\n",
    "            \n",
    "            # Extract EMG window and compute its envelope using moving average\n",
    "            emg_windows[stimuli_idx][repetition_idx] = emg[idx, :]\n",
    "            emg_envelopes[stimuli_idx][repetition_idx] = convolve1d(\n",
    "                emg_windows[stimuli_idx][repetition_idx], \n",
    "                mov_mean_weights, \n",
    "                axis=0\n",
    "            )\n",
    "    \n",
    "    # Store processed data for this subject\n",
    "    processed_data[subject] = {\n",
    "        \"emg_windows\": emg_windows,\n",
    "        \"emg_envelopes\": emg_envelopes\n",
    "    }\n",
    "\n",
    "print(\"Preprocessing completed for all subjects!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
